{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "import math\n",
    "import time, pickle, math, warnings, os, operator\n",
    "import string \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.translate import bleu_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following path could be changed to your own file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = './dataset/'\n",
    "path_train = base+'train.tsv'\n",
    "path_test_source = base+'source.txt'\n",
    "path_test_target = base+'target.txt'\n",
    "\n",
    "train_dataset = [line.strip() for line in open(path_train)]\n",
    "source_test = [line.strip() for line in open(path_test_source)]\n",
    "target_test = [line.strip() for line in open(path_test_target)]\n",
    "\n",
    "punctuations = string.punctuation.replace(\"\\\"\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processTrainDataset(train_dataset):\n",
    "    source_train = []\n",
    "    target_train = []\n",
    "    for data in train_dataset:\n",
    "        data_group = data.split(\"\\t\")\n",
    "        target = data_group[1]\n",
    "        source = data_group[0].translate(str.maketrans({key: \" {0} \".format(key) for key in punctuations}))\n",
    "        source_train.append(source)\n",
    "        target_train.append(target)\n",
    "    return source_train,target_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processTestDataset(source_test):\n",
    "    new_source_test = []\n",
    "    for data in source_test:\n",
    "        new_data = data.split(\"code2comment :\")[1].translate(str.maketrans({key: \" {0} \".format(key) for key in punctuations}))\n",
    "        new_source_test.append(new_data)\n",
    "    return new_source_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process the raw data and transform into BOW vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_train,target_train = processTrainDataset(train_dataset)\n",
    "source_test = processTestDataset(source_test)\n",
    "\n",
    "data_count_vect = CountVectorizer(max_df=0.5)\n",
    "train_data_vect = data_count_vect.fit_transform(source_train)\n",
    "test_data_vect = data_count_vect.transform(source_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text similairty techniques: Gestalt Pattern Matching "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictionTopk(topk,similarity, similarity_time):\n",
    "    print(\"processing:\",topk)\n",
    "    prediction = []  \n",
    "    start_time = time.time()\n",
    "    for index in range(len(similarity)):\n",
    "        if index%1000 == 0:\n",
    "            print(\"processing-instance \",index,\"/16780\")\n",
    "#       find top-10 instances based on cosine distance\n",
    "        index_nn = np.argpartition(similarity[index], -10)[-10:]\n",
    "        similar_nn = []\n",
    "        for idx in index_nn:\n",
    "#       find best 10 candidates from top-10 instances based on text similarity score\n",
    "            similar_score = similar(source_test[index], source_train[idx])\n",
    "            similar_nn.append((idx, similar_score))\n",
    "        similar_nn.sort(key=lambda x:x[1], reverse=True)\n",
    "        similar_topk = similar_nn[:topk]\n",
    "        current_prediction = []\n",
    "        for element in similar_topk:\n",
    "            current_prediction.append(target_train[element[0]])\n",
    "        prediction.append(current_prediction)\n",
    "    print(topk, \" time cost:\", time.time() - start_time + similarity_time,\"s\")\n",
    "#   write the recommendation comments to the file named as \"our_predictions_k.txt\"\n",
    "    with open(base+'our_predictions_'+str(topk) + '.txt', 'w') as f:\n",
    "        for data in prediction:\n",
    "            for element in data:\n",
    "                f.write(element + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing: 1\n",
      "processing-instance  0 /16780\n",
      "processing-instance  1000 /16780\n",
      "processing-instance  2000 /16780\n",
      "processing-instance  3000 /16780\n",
      "processing-instance  4000 /16780\n",
      "processing-instance  5000 /16780\n",
      "processing-instance  6000 /16780\n",
      "processing-instance  7000 /16780\n",
      "processing-instance  8000 /16780\n",
      "processing-instance  9000 /16780\n",
      "processing-instance  10000 /16780\n",
      "processing-instance  11000 /16780\n",
      "processing-instance  12000 /16780\n",
      "processing-instance  13000 /16780\n",
      "processing-instance  14000 /16780\n",
      "processing-instance  15000 /16780\n",
      "processing-instance  16000 /16780\n",
      "1  time cost: 240.7754499912262 s\n",
      "processing: 3\n",
      "processing-instance  0 /16780\n",
      "processing-instance  1000 /16780\n",
      "processing-instance  2000 /16780\n",
      "processing-instance  3000 /16780\n",
      "processing-instance  4000 /16780\n",
      "processing-instance  5000 /16780\n",
      "processing-instance  6000 /16780\n",
      "processing-instance  7000 /16780\n",
      "processing-instance  8000 /16780\n",
      "processing-instance  9000 /16780\n",
      "processing-instance  10000 /16780\n",
      "processing-instance  11000 /16780\n",
      "processing-instance  12000 /16780\n",
      "processing-instance  13000 /16780\n",
      "processing-instance  14000 /16780\n",
      "processing-instance  15000 /16780\n",
      "processing-instance  16000 /16780\n",
      "3  time cost: 249.29245948791504 s\n",
      "processing: 5\n",
      "processing-instance  0 /16780\n",
      "processing-instance  1000 /16780\n",
      "processing-instance  2000 /16780\n",
      "processing-instance  3000 /16780\n",
      "processing-instance  4000 /16780\n",
      "processing-instance  5000 /16780\n",
      "processing-instance  6000 /16780\n",
      "processing-instance  7000 /16780\n",
      "processing-instance  8000 /16780\n",
      "processing-instance  9000 /16780\n",
      "processing-instance  10000 /16780\n",
      "processing-instance  11000 /16780\n",
      "processing-instance  12000 /16780\n",
      "processing-instance  13000 /16780\n",
      "processing-instance  14000 /16780\n",
      "processing-instance  15000 /16780\n",
      "processing-instance  16000 /16780\n",
      "5  time cost: 250.54326462745667 s\n",
      "processing: 10\n",
      "processing-instance  0 /16780\n",
      "processing-instance  1000 /16780\n",
      "processing-instance  2000 /16780\n",
      "processing-instance  3000 /16780\n",
      "processing-instance  4000 /16780\n",
      "processing-instance  5000 /16780\n",
      "processing-instance  6000 /16780\n",
      "processing-instance  7000 /16780\n",
      "processing-instance  8000 /16780\n",
      "processing-instance  9000 /16780\n",
      "processing-instance  10000 /16780\n",
      "processing-instance  11000 /16780\n",
      "processing-instance  12000 /16780\n",
      "processing-instance  13000 /16780\n",
      "processing-instance  14000 /16780\n",
      "processing-instance  15000 /16780\n",
      "processing-instance  16000 /16780\n",
      "10  time cost: 248.3625237941742 s\n"
     ]
    }
   ],
   "source": [
    "# Compute the cosine distance and its computational time\n",
    "similarity_start_time = time.time()\n",
    "similarity = cosine_similarity(test_data_vect, train_data_vect)\n",
    "similarity_time = time.time() - similarity_start_time\n",
    "# Compute the text similarity (GPM) and results\n",
    "predictionTopk(1,similarity,similarity_time)\n",
    "predictionTopk(3,similarity,similarity_time)\n",
    "predictionTopk(5,similarity,similarity_time)\n",
    "predictionTopk(10,similarity,similarity_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k candidates:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16780/16780 [00:04<00:00, 4001.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PP    : 470/16780 (%2.80)\n",
      "BLEU mean              :  0.1241197518103609\n",
      "k candidates:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16780/16780 [00:12<00:00, 1388.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PP    : 566/16780 (%3.37)\n",
      "BLEU mean              :  0.18330366896295064\n",
      "k candidates:  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16780/16780 [00:20<00:00, 834.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PP    : 605/16780 (%3.61)\n",
      "BLEU mean              :  0.20872034649762677\n",
      "k candidates:  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 11265/16780 [00:26<00:12, 432.31it/s]"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "from nltk.translate import bleu_score\n",
    "from tqdm import tqdm\n",
    "chencherry = bleu_score.SmoothingFunction()\n",
    "\n",
    "# Evaluate perfect prediction & BLEU score of our approach\n",
    "for k in [1, 3, 5, 10]:\n",
    "\n",
    "    print('k candidates: ', k)\n",
    "    path_targets = base + 'target.txt'\n",
    "    path_predictions = base + 'our_predictions_' + str(k) + '.txt'\n",
    "\n",
    "    tgt = [line.strip() for line in open(path_targets)]\n",
    "    pred = [line.strip() for line in open(path_predictions)]\n",
    "\n",
    "    count_perfect = 0\n",
    "    BLEUscore = []\n",
    "    for i in tqdm(range(len(tgt))):\n",
    "        best_BLEU = 0\n",
    "        target = tgt[i]\n",
    "        for prediction in pred[i*k:i*k+k]:\n",
    "            if \" \".join(prediction.split()) == \" \".join(target.split()):\n",
    "                count_perfect += 1\n",
    "                best_BLEU = bleu_score.sentence_bleu([target], prediction, smoothing_function=chencherry.method1)\n",
    "                break\n",
    "            current_BLEU = bleu_score.sentence_bleu([target], prediction, smoothing_function=chencherry.method1)\n",
    "            if current_BLEU > best_BLEU:\n",
    "                best_BLEU = current_BLEU\n",
    "        BLEUscore.append(best_BLEU)\n",
    "\n",
    "    print(f'PP    : %d/%d (%s%.2f)' % (count_perfect, len(tgt), '%', (count_perfect * 100) / len(tgt)))\n",
    "    print(f'BLEU mean              : ', statistics.mean(BLEUscore))\n",
    "    \n",
    "    with open(base+\"bleu_\"+str(k) + '.txt', 'w') as fs:\n",
    "        for bleu in BLEUscore:\n",
    "            fs.write(str(bleu) + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neo_env",
   "language": "python",
   "name": "neo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
