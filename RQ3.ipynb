{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "import math\n",
    "import time, pickle, math, warnings, os, operator\n",
    "import string \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.translate import bleu_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following path could be changed to your own file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = './dataset/'\n",
    "path_train = base+'train.tsv'\n",
    "path_test_source = base+'source.txt'\n",
    "path_test_target = base+'target.txt'\n",
    "\n",
    "train_dataset = [line.strip() for line in open(path_train)]\n",
    "source_test = [line.strip() for line in open(path_test_source)]\n",
    "target_test = [line.strip() for line in open(path_test_target)]\n",
    "\n",
    "punctuations = string.punctuation.replace(\"\\\"\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processTrainDataset(train_dataset):\n",
    "    source_train = []\n",
    "    target_train = []\n",
    "    for data in train_dataset:\n",
    "        data_group = data.split(\"\\t\")\n",
    "        target = data_group[1]\n",
    "        source = data_group[0].translate(str.maketrans({key: \" {0} \".format(key) for key in punctuations}))\n",
    "        source_train.append(source)\n",
    "        target_train.append(target)\n",
    "    return source_train,target_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processTestDataset(source_test):\n",
    "    new_source_test = []\n",
    "    for data in source_test:\n",
    "        new_data = data.split(\"code2comment :\")[1].translate(str.maketrans({key: \" {0} \".format(key) for key in punctuations}))\n",
    "        new_source_test.append(new_data)\n",
    "    return new_source_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process the raw data and transform into BOW vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_train,target_train = processTrainDataset(train_dataset)\n",
    "source_test = processTestDataset(source_test)\n",
    "\n",
    "data_count_vect = CountVectorizer(max_df=0.5)\n",
    "train_data_vect = data_count_vect.fit_transform(source_train)\n",
    "test_data_vect = data_count_vect.transform(source_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text similairty techniques: Gestalt Pattern Matching "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from strsimpy.levenshtein import Levenshtein\n",
    "from strsimpy.normalized_levenshtein import NormalizedLevenshtein\n",
    "from strsimpy.damerau import Damerau\n",
    "from strsimpy.jaro_winkler import JaroWinkler\n",
    "from strsimpy.metric_lcs import MetricLCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictionResultByTextSimilarity(similarity, algorithm, name, time):\n",
    "    print(\"start predicting\", name)\n",
    "    topk = 10\n",
    "    start_time = time.time()\n",
    "    prediction = []\n",
    "#     set variable algorithm as a selected text similarity technique\n",
    "    algorithm = algorithm()   \n",
    "    for index in range(len(similarity)):\n",
    "        index_nn = np.argpartition(similarity[index], -topk)[-topk:]\n",
    "        if index%1000 == 0:\n",
    "            print(\"processing-instance \",index,\"/16780\")\n",
    "        sq2sq_max_value = index_nn[0]\n",
    "        sq2sq_best_score = algorithm.distance(source_test[0], source_train[0])\n",
    "        for idx in index_nn:\n",
    "            sq2sq_score = algorithm.distance(source_test[index], source_train[idx])\n",
    "            if sq2sq_score < sq2sq_best_score:\n",
    "                sq2sq_best_score = sq2sq_score\n",
    "                sq2sq_max_value = idx\n",
    "        prediction.append(target_train[sq2sq_max_value])\n",
    "    pp = 0\n",
    "    pp_comment = []\n",
    "    for index in range(len(prediction)):\n",
    "        if prediction[index] == target_test[index]:\n",
    "            pp_comment.append({\"index\": index, \"prediction\":prediction[index], \"target\": target_test[index]})\n",
    "            pp += 1\n",
    "    print(name,\":pp length is \", len(pp_comment), \"time cost:\", time.time() - start_time + time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RQ3 Compute the text similarity component and generate results perfect prediction & computational time when best-candidate=1. \n",
    "\n",
    "# Compute the cosine distance metric\n",
    "cos_similarity_time = time.time()\n",
    "similarity = cosine_similarity(test_data_vect, train_data_vect)\n",
    "similarity_time = time.time() - cos_similarity_time\n",
    "\n",
    "# The abbreviation of each technique for Figure 3 in the paper.\n",
    "# LD + Cosine\n",
    "predictionResultByTextSimilarity(similarity, Levenshtein, \"Levenshtein\",cos_similarity_time)\n",
    "# NLD + Cosine\n",
    "predictionResultByTextSimilarity(similarity, NormalizedLevenshtein, \"NormalizedLevenshtein\",cos_similarity_time)\n",
    "# DLD + Cosine\n",
    "predictionResultByTextSimilarity(similarity, Damerau, \"Damerau\",cos_similarity_time)\n",
    "# JWD + Cosine\n",
    "predictionResultByTextSimilarity(similarity, JaroWinkler, \"JaroWinkler\",cos_similarity_time)\n",
    "# MLCS + Cosine\n",
    "predictionResultByTextSimilarity(similarity, MetricLCS, \"MetricLCS\",cos_similarity_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RQ3 Compute the distance metrics component and generate results perfect prediction & computational time when best-candidate=1. \n",
    "from difflib import SequenceMatcher\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.metrics.pairwise import manhattan_distances\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "def predictionResultByDistanceMetric(topk,similarity,name,distance_time):\n",
    "    print(\"start predicting\", name)\n",
    "    prediction = []  \n",
    "    start_time = time.time()\n",
    "    for index in range(len(similarity)):\n",
    "        if index%1000 == 0:\n",
    "            print(\"processing-instance \",index,\"/16780\")\n",
    "        index_nn = similarity[index].argsort()[:10]\n",
    "        similar_nn = []\n",
    "        for idx in index_nn:\n",
    "            similar_score = similar(source_test[index], source_train[idx])\n",
    "            similar_nn.append((idx, similar_score))\n",
    "        similar_nn.sort(key=lambda x:x[1], reverse=True)\n",
    "        similar_topk = similar_nn[:topk]\n",
    "        current_prediction = []\n",
    "        for element in similar_topk:\n",
    "            current_prediction.append(target_train[element[0]])\n",
    "        prediction.append(current_prediction[0])\n",
    "    pp = 0\n",
    "    pp_comment = []\n",
    "    for index in range(len(prediction)):\n",
    "        if prediction[index] == target_test[index]:\n",
    "            pp_comment.append({\"index\": index, \"prediction\":prediction[index], \"target\": target_test[index]})\n",
    "            pp += 1\n",
    "    print(name,\":pp length is \", len(pp_comment), \"time cost:\", time.time() - start_time + distance_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start predicting euc\n",
      "processing-instance  0 /16780\n",
      "processing-instance  1000 /16780\n",
      "processing-instance  2000 /16780\n",
      "processing-instance  3000 /16780\n",
      "processing-instance  4000 /16780\n",
      "processing-instance  5000 /16780\n",
      "processing-instance  6000 /16780\n",
      "processing-instance  7000 /16780\n",
      "processing-instance  8000 /16780\n",
      "processing-instance  9000 /16780\n",
      "processing-instance  10000 /16780\n",
      "processing-instance  11000 /16780\n",
      "processing-instance  12000 /16780\n",
      "processing-instance  13000 /16780\n",
      "processing-instance  14000 /16780\n",
      "processing-instance  15000 /16780\n",
      "processing-instance  16000 /16780\n",
      "euc :pp length is  414 time cost: 394.04774808883667\n"
     ]
    }
   ],
   "source": [
    "# Compute Euclidean distance + GPM\n",
    "distance_start_time = time.time()\n",
    "similarity = euclidean_distances(test_data_vect,train_data_vect)\n",
    "distance_time = time.time()-distance_start_time\n",
    "\n",
    "predictionResultByDistanceMetric(1,similarity,\"euc\",distance_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start predicting manh\n",
      "processing-instance  0 /16780\n",
      "processing-instance  1000 /16780\n",
      "processing-instance  2000 /16780\n",
      "processing-instance  3000 /16780\n",
      "processing-instance  4000 /16780\n",
      "processing-instance  5000 /16780\n",
      "processing-instance  6000 /16780\n",
      "processing-instance  7000 /16780\n",
      "processing-instance  8000 /16780\n",
      "processing-instance  9000 /16780\n",
      "processing-instance  10000 /16780\n",
      "processing-instance  11000 /16780\n",
      "processing-instance  12000 /16780\n",
      "processing-instance  13000 /16780\n",
      "processing-instance  14000 /16780\n",
      "processing-instance  15000 /16780\n",
      "processing-instance  16000 /16780\n",
      "manh :pp length is  450 time cost: 392.708637714386\n"
     ]
    }
   ],
   "source": [
    "# Compute Manhattan distance + GPM\n",
    "distance_start_time = time.time()\n",
    "similarity = manhattan_distances(test_data_vect,train_data_vect)\n",
    "distance_time = time.time()-distance_start_time\n",
    "\n",
    "predictionResultByDistanceMetric(1,similarity,\"manh\",distance_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neo_env",
   "language": "python",
   "name": "neo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
